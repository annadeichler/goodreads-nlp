{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os,re,shutil,pickle\n",
    "import gdown,gzip\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datalist(typ=None):\n",
    "    #download and extract selected dataset in json format\n",
    "    gdrive_csv_url ='https://raw.githubusercontent.com/MengtingWan/goodreads/master/gdrive_id.csv'\n",
    "    datasets_df = pd.read_csv(gdrive_csv_url, error_bad_lines=False)\n",
    "    datasets_map = dict(zip(datasets_df['name'].values, datasets_df['id'].values))\n",
    "    dfdmap=pd.DataFrame(datasets_map.items(),columns=['file','link'])\n",
    "    dfdmap['type']=dfdmap['file'].apply(lambda x: x.split('_')[1].rsplit('.')[0])\n",
    "    dfdmap['content']=dfdmap['file'].apply(lambda x: x.split('.')[0].split('_')[2:])\n",
    "    dfdmap=dfdmap.sort_values(by=['type'])\n",
    "    if typ!=None:\n",
    "        dfdmap = dfdmap[dfdmap.type==typ]\n",
    "    dfdmap=dfdmap.reset_index(drop=True)\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "        display(dfdmap[['type','content']])\n",
    "    return dfdmap\n",
    "\n",
    "def download_data(ddir,selected_id,data_sources):\n",
    "    source_id=data_sources.iloc[selected_id].link\n",
    "    file_name = data_sources.iloc[selected_id].file\n",
    "    json_file = os.path.join(DIR,file_name.rstrip('.gz'))\n",
    "    if os.path.exists(os.path.join(ddir,json_file)):\n",
    "        return json_file\n",
    "    else:\n",
    "        if not os.path.exists(os.path.join(ddir,file_name)):\n",
    "            gdrive_url='https://drive.google.com/uc?id='+source_id\n",
    "            gdown.download(gdrive_url, output=os.path.join(ddir,file_name),quiet=True)\n",
    "            print(\"downloaded file\")\n",
    "            print(\"extracting\")\n",
    "        with gzip.open(os.path.join(ddir,file_name), 'rb') as f_in:\n",
    "            with open(json_file, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    return json_file\n",
    "\n",
    "def get_sentiment(df):\n",
    "    df = df.drop(df[df.rating ==0].index)\n",
    "    df.loc[df['rating']<3,'sentiment']=0\n",
    "    df.loc[df['rating']>3,'sentiment']=1\n",
    "    df=df[df.rating!=3]\n",
    "    return df\n",
    "\n",
    "def process_text(df,m1,m2):\n",
    "\n",
    "    RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n",
    "    df['review_text']=df['review_text'].str.lower() \n",
    "    df['review_text'].replace(m1, regex=True, inplace=True)\n",
    "    df['review_text'].replace(m2, regex=True, inplace=True)\n",
    "    df['review_text'].replace(regex=True,inplace=True,to_replace=r'\\n',value=r'')\n",
    "    df['review_text'].replace(regex=True,inplace=True,to_replace=r'[0-9]{1,3} stars{0,1}',value=r'')\n",
    "    df['review_text'].replace(regex=True,inplace=True,to_replace=r'[0-9]{1,3} out of [0-9]{0,1}',value=r'')\n",
    "    df['review_text']=df['review_text'].str.replace(RE_PUNCTUATION, \"\")\n",
    "    df = df[df.review_text.str.contains(r'[a-z]')]\n",
    "    return df\n",
    "\n",
    "def get_word_freqs(df):\n",
    "    return nltk.FreqDist(df.review_text.values)\n",
    "\n",
    "def remove_spam(df,full_reviews,partial_reviews):\n",
    "    df= df[~df['review_text'].isin(full_reviews)]\n",
    "    return df[np.where(df.review_text.str.contains('|'.join(partial_reviews)),False,True)]\n",
    "\n",
    "def get_dataframe(json_file,chunk_size=250000,n_entries=1e7,cols=None):\n",
    "    with open('review_text_filters.pickle', 'rb') as handle:\n",
    "        review_filters = pickle.load(handle)\n",
    "    df_reader=pd.read_json(json_file,lines=True,chunksize=chunk_size)\n",
    "    n,count=0,0\n",
    "    ll,times=[],[]\n",
    "    for chunk in df_reader:\n",
    "        print(\"processing\")\n",
    "        if cols:         \n",
    "            chunk = chunk[cols]\n",
    "        n+=len(chunk)\n",
    "        chunk = get_sentiment(chunk)\n",
    "        chunk = process_text(chunk,review_filters['replace_abbrs'],\n",
    "                             review_filters['replace_else'])\n",
    "        chunk = remove_spam(chunk,review_filters['full_reviews'],review_filters['partial_reviews'])\n",
    "        ll.append(chunk)\n",
    "        print(str(round(n/n_entries,2)*100)+\"%\")\n",
    "        if n%n_entries==0:\n",
    "            break\n",
    "    df=pd.concat(ll,axis=0,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[history, biography]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[spoiler]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[children]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[poetry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[dedup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[young, adult]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[comics, graphic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[spoiler, raw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[mystery, thriller, crime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reviews</td>\n",
       "      <td>[fantasy, paranormal]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                     content\n",
       "0   reviews        [history, biography]\n",
       "1   reviews                   [romance]\n",
       "2   reviews                   [spoiler]\n",
       "3   reviews                  [children]\n",
       "4   reviews                    [poetry]\n",
       "5   reviews                     [dedup]\n",
       "6   reviews              [young, adult]\n",
       "7   reviews           [comics, graphic]\n",
       "8   reviews              [spoiler, raw]\n",
       "9   reviews  [mystery, thriller, crime]\n",
       "10  reviews       [fantasy, paranormal]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_sources = get_datalist('reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file       goodreads_reviews_children.json.gz\n",
       "link        1908GDMdrhDN7sTaI_FelSHxbwcNM1EzR\n",
       "type                                  reviews\n",
       "content                            [children]\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_id=3\n",
    "data_sources.iloc[selected_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded file\n",
      "extracting\n"
     ]
    }
   ],
   "source": [
    "DIR='./data/'\n",
    "json_file=download_data(DIR,selected_id,data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['book_id', 'date_added', 'date_updated', 'n_comments', 'n_votes',\n",
      "       'rating', 'read_at', 'review_id', 'review_text', 'started_at',\n",
      "       'user_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_reader=pd.read_json(json_file,lines=True,chunksize=1e4)\n",
    "for chunk in df_reader:\n",
    "    print(chunk.columns)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>read_at</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>started_at</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23310161</td>\n",
       "      <td>Tue Nov 17 11:37:35 -0800 2015</td>\n",
       "      <td>Tue Nov 17 11:38:05 -0800 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>f4b4b050f4be00e9283c92a814af2670</td>\n",
       "      <td>Fun sequel to the original.</td>\n",
       "      <td></td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17290220</td>\n",
       "      <td>Sat Nov 08 08:54:03 -0800 2014</td>\n",
       "      <td>Wed Jan 25 13:56:12 -0800 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tue Jan 24 00:00:00 -0800 2017</td>\n",
       "      <td>22d424a2b0057b18fb6ecf017af7be92</td>\n",
       "      <td>One of my favorite books to read to my 5 year ...</td>\n",
       "      <td></td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6954929</td>\n",
       "      <td>Thu Oct 23 13:46:20 -0700 2014</td>\n",
       "      <td>Thu Oct 23 13:47:00 -0700 2014</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>50ed4431c451d5677d98dd25ca8ec106</td>\n",
       "      <td>One of the best and most imaginative childrens...</td>\n",
       "      <td></td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460548</td>\n",
       "      <td>Mon Dec 02 10:43:59 -0800 2013</td>\n",
       "      <td>Wed Mar 22 11:47:25 -0700 2017</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>1e4de11dd4fa4b7ffa59b6c69a6b28e9</td>\n",
       "      <td>My daughter is loving this. Published in the 6...</td>\n",
       "      <td></td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11474551</td>\n",
       "      <td>Wed May 11 22:38:11 -0700 2011</td>\n",
       "      <td>Sun Jan 29 15:56:41 -0800 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Wed May 11 00:00:00 -0700 2011</td>\n",
       "      <td>2065145714bf747083a1c9ce81d5c4fe</td>\n",
       "      <td>A friend sent me this. Hilarious!</td>\n",
       "      <td>Wed May 11 00:00:00 -0700 2011</td>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                      date_added                    date_updated  \\\n",
       "0  23310161  Tue Nov 17 11:37:35 -0800 2015  Tue Nov 17 11:38:05 -0800 2015   \n",
       "1  17290220  Sat Nov 08 08:54:03 -0800 2014  Wed Jan 25 13:56:12 -0800 2017   \n",
       "2   6954929  Thu Oct 23 13:46:20 -0700 2014  Thu Oct 23 13:47:00 -0700 2014   \n",
       "3    460548  Mon Dec 02 10:43:59 -0800 2013  Wed Mar 22 11:47:25 -0700 2017   \n",
       "4  11474551  Wed May 11 22:38:11 -0700 2011  Sun Jan 29 15:56:41 -0800 2012   \n",
       "\n",
       "   n_comments  n_votes  rating                         read_at  \\\n",
       "0           0        7       4                                   \n",
       "1           0        4       5  Tue Jan 24 00:00:00 -0800 2017   \n",
       "2           1        6       5                                   \n",
       "3           4        5       5                                   \n",
       "4           0        5       5  Wed May 11 00:00:00 -0700 2011   \n",
       "\n",
       "                          review_id  \\\n",
       "0  f4b4b050f4be00e9283c92a814af2670   \n",
       "1  22d424a2b0057b18fb6ecf017af7be92   \n",
       "2  50ed4431c451d5677d98dd25ca8ec106   \n",
       "3  1e4de11dd4fa4b7ffa59b6c69a6b28e9   \n",
       "4  2065145714bf747083a1c9ce81d5c4fe   \n",
       "\n",
       "                                         review_text  \\\n",
       "0                        Fun sequel to the original.   \n",
       "1  One of my favorite books to read to my 5 year ...   \n",
       "2  One of the best and most imaginative childrens...   \n",
       "3  My daughter is loving this. Published in the 6...   \n",
       "4                  A friend sent me this. Hilarious!   \n",
       "\n",
       "                       started_at                           user_id  \n",
       "0                                  8842281e1d1347389f2ab93d60773d4d  \n",
       "1                                  8842281e1d1347389f2ab93d60773d4d  \n",
       "2                                  8842281e1d1347389f2ab93d60773d4d  \n",
       "3                                  8842281e1d1347389f2ab93d60773d4d  \n",
       "4  Wed May 11 00:00:00 -0700 2011  8842281e1d1347389f2ab93d60773d4d  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing\n",
      "50.0%\n",
      "processing\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 25000\n",
    "N = 0.5e5\n",
    "cols_reviews = ['book_id','review_id','review_text','rating']\n",
    "df = get_dataframe(json_file,chunk_size=chunk_size,n_entries=N,cols=cols_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23310161</td>\n",
       "      <td>f4b4b050f4be00e9283c92a814af2670</td>\n",
       "      <td>fun sequel to the original</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17290220</td>\n",
       "      <td>22d424a2b0057b18fb6ecf017af7be92</td>\n",
       "      <td>one of my favorite books to read to my 5 year ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6954929</td>\n",
       "      <td>50ed4431c451d5677d98dd25ca8ec106</td>\n",
       "      <td>one of the best and most imaginative childrens...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460548</td>\n",
       "      <td>1e4de11dd4fa4b7ffa59b6c69a6b28e9</td>\n",
       "      <td>my daughter is loving this published in the 60...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11474551</td>\n",
       "      <td>2065145714bf747083a1c9ce81d5c4fe</td>\n",
       "      <td>a friend sent me this hilarious</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                         review_id  \\\n",
       "0  23310161  f4b4b050f4be00e9283c92a814af2670   \n",
       "1  17290220  22d424a2b0057b18fb6ecf017af7be92   \n",
       "2   6954929  50ed4431c451d5677d98dd25ca8ec106   \n",
       "3    460548  1e4de11dd4fa4b7ffa59b6c69a6b28e9   \n",
       "4  11474551  2065145714bf747083a1c9ce81d5c4fe   \n",
       "\n",
       "                                         review_text  rating  sentiment  \n",
       "0                         fun sequel to the original       4        1.0  \n",
       "1  one of my favorite books to read to my 5 year ...       5        1.0  \n",
       "2  one of the best and most imaginative childrens...       5        1.0  \n",
       "3  my daughter is loving this published in the 60...       5        1.0  \n",
       "4                    a friend sent me this hilarious       5        1.0  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample example reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling negative reviews: \n",
      "\n",
      "Review(s): \n",
      "this book was really bad  terribly tremendously bad  i mean the girls thought about staying with her dad is fine but the constant regret she had the way she wanted to be friends with a lonely unpopular girl but was afraid to because of her super popular best friend jesus  it was awful  this book was put in the ya section the ya section  the girl in the book sounded nine or ten  there was nothing young adult about this book either  overall really bad bad bad bad book\n",
      "\n",
      "Review(s): \n",
      "typical dr seuss fare it was notone of my favourites as a kid but i liked it okay\n",
      "\n",
      "Review(s): \n",
      "i think that when you read this book you need to be aware of this story i wasnt so i did not really care for it i am not sure this event happened or anything  but overall i did not like the book because of the way the characters were drawn and because of the way the story was written i understood what the story was about but it really it was notreally focused on the fact that ariel was a spy i do not think this was entertaining nor even for children\n",
      "\n",
      "sampling positive reviews: \n",
      "\n",
      "Review(s): \n",
      "it is been years since olivia first took readers by the heart her exuberance and uniqueness have not lessened or grown stale as many other series characters sadly do after a long run in this volume olivia is having an identity crisis  she is tired of conformity and does not want to be a princess  unless it is one from india thailand africa or china and she is right there are more options that pink sparkly fairy princesses olivia is a true iconoclast  who else would go to the school halloween party as a warthog and bravo olivia for wanting to expose corporate malfeasance kudos to falconer for never talking down to children and for breaking stereotypes this is a wonderful addition to the olivia cannon and olivia my dear  it is good to be queen\n",
      "\n",
      "Review(s): \n",
      "these are wonderful books for an early reader the stories are simple but engaging even an adult would have fun bunny and jack are great characters they pun their way to solution after solution\n",
      "\n",
      "Review(s): \n",
      "near perfect illustrations of many of the birds we see around us accompanied by very simple statements about birds in general wonderful introduction to birding for the little ones\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_reviews=3\n",
    "print(\"sampling negative reviews: \\n\")\n",
    "_=[print(\"Review(s): \"+\"\\n\"+x[:1000]+\"\\n\") \n",
    "       for i,x in enumerate(df[df[\"sentiment\"] == 0].sample(n_reviews).review_text.values)]\n",
    "print(\"sampling positive reviews: \\n\")\n",
    "_=[print(\"Review(s): \"+\"\\n\"+x[:1000]+\"\\n\") \n",
    "       for i,x in enumerate(df[df[\"sentiment\"] == 1].sample(n_reviews).review_text.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further processing with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "# choose random reviews\n",
    "chosen_idx = np.random.choice(len(df), replace=False, size=1)\n",
    "text = df.iloc[chosen_idx].review_text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[an, imagination, library, book, sam, has, had, for, a, while, but, that, continues, to, be, a, favorite, it, is, pretty, simple, with, cute, illustrations, and, a, nice, rhythm, and, repetition]\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "doc=nlp(text)\n",
    "print([token for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an an DET\n",
      "imagination imagination NOUN\n",
      "library library NOUN\n",
      "book book NOUN\n",
      "sam sam PROPN\n",
      "has have AUX\n",
      "had have VERB\n",
      "for for ADP\n",
      "a a DET\n",
      "while while NOUN\n",
      "but but CCONJ\n",
      "that that DET\n",
      "continues continue VERB\n",
      "to to PART\n",
      "be be AUX\n",
      "a a DET\n",
      "favorite favorite ADJ\n",
      "it -PRON- PRON\n",
      "is be AUX\n",
      "pretty pretty ADV\n",
      "simple simple ADJ\n",
      "with with ADP\n",
      "cute cute ADJ\n",
      "illustrations illustration NOUN\n",
      "and and CCONJ\n",
      "a a DET\n",
      "nice nice ADJ\n",
      "rhythm rhythm NOUN\n",
      "and and CCONJ\n",
      "repetition repetition NOUN\n"
     ]
    }
   ],
   "source": [
    "# display word stems via leammatization and POS tagging\n",
    "doc=nlp(text)\n",
    "for word in doc:\n",
    "    print(word.text,word.lemma_,word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "punctuations = string.punctuation\n",
    "parser=English()\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = nlp(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    return mytokens\n",
    "\n",
    "def clean_text(text):\n",
    "    return str(text).strip().lower()\n",
    "\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# good for detecting nans in dataset\n",
    "# df_sub =df_sub[~df_sub.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "X = df['review_text']\n",
    "ylabels=df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mlp3)",
   "language": "python",
   "name": "mlp3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
